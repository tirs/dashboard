# Quick Reference: Data Management

## ğŸš€ One-Minute Summary

### DEMO (Current - Local Testing)
```bash
streamlit run app.py
# Data: 100 hardcoded sales + 3 demo users
# Storage: Local DuckDB file
# Users: Demo credentials (admin/admin123, etc.)
```

### PRODUCTION (What You'll Deploy)
```bash
docker-compose up -d
# Data: Real-time from APIs, databases, files
# Storage: DuckDB + S3 backups
# Users: SSO/LDAP + manual registration
# Updates: Automated daily at 2 AM + hourly health checks
```

---

## ğŸ“‹ Command Reference

### Get Started with Production Data Sync

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. One-time data import (choose one)
python scripts/data_sync.py sync-sales --csv example_sales.csv
python scripts/data_sync.py import-users example_users.csv
python scripts/data_sync.py sync-sales --api "https://api.company.com/sales" --days 30

# 3. Verify everything loaded
python scripts/data_sync.py health-check

# 4. Create backup
python scripts/data_sync.py backup

# 5. Start automated sync (production)
python scripts/data_sync.py start-scheduler &
streamlit run app.py
```

---

## ğŸ”Œ Data Source Integration Examples

### CSV File Import
```bash
python scripts/data_sync.py sync-sales --csv sales_data.csv
```

### Daily API Sync
```bash
# Runs automatically at 2 AM
python scripts/data_sync.py sync-sales --api "https://your-api.com/sales" --days 1
```

### Shopify Integration
```python
from scripts.enterprise_integrations import ShopifyConnector

shopify = ShopifyConnector()
orders = shopify.fetch_orders(days_back=1)
sales = shopify.transform_to_sales(orders)
# Insert into DuckDB...
```

### Salesforce Integration
```python
from scripts.enterprise_integrations import SalesforceConnector

sf = SalesforceConnector()
opportunities = sf.fetch_opportunities(days_back=7)
# Process and insert...
```

---

## ğŸ—‚ï¸ File Structure (Production Ready)

```
c:/Users/simba/Desktop/data/
â”œâ”€â”€ app.py                              Main app
â”œâ”€â”€ requirements.txt                    Dependencies (UPDATED)
â”œâ”€â”€ docker-compose.yml                  Production deployment
â”œâ”€â”€ Dockerfile                          Container config
â”œâ”€â”€ nginx.conf                          Reverse proxy
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ auth.py                         Authentication
â”‚   â”œâ”€â”€ config.py                       Styling
â”‚   â”œâ”€â”€ db.py                           Database layer
â”‚   â”œâ”€â”€ sidebar.py                      NEW: Advanced navigation
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ analytics.py
â”‚       â”œâ”€â”€ data_browser.py
â”‚       â”œâ”€â”€ reports.py
â”‚       â”œâ”€â”€ users.py
â”‚       â”œâ”€â”€ settings.py
â”‚       â””â”€â”€ profile.py (FIXED)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_sync.py                    NEW: Production data sync
â”‚   â”œâ”€â”€ enterprise_integrations.py      NEW: Enterprise connectors
â”‚   â”œâ”€â”€ example_sales_import.csv        NEW: Sample sales data
â”‚   â””â”€â”€ example_users_import.csv        NEW: Sample users data
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dashboard.duckdb                Database (persistent)
â”‚
â”œâ”€â”€ backups/                            NEW: Backup storage
â”‚   â””â”€â”€ dashboard_backup_*.duckdb       Automatic backups
â”‚
â”œâ”€â”€ logs/                               NEW: Logging
â”‚   â””â”€â”€ data_sync.log                   Sync activity log
â”‚
â””â”€â”€ Documentation/
    â”œâ”€â”€ README.md                       Main guide
    â”œâ”€â”€ PRODUCTION_DATA_STRATEGY.md     NEW: Strategies
    â”œâ”€â”€ PRODUCTION_DATA_SYNC_GUIDE.md   NEW: Implementation
    â”œâ”€â”€ DEMO_vs_PRODUCTION_SUMMARY.md   NEW: Comparison
    â””â”€â”€ QUICK_REFERENCE.md              You are here
```

---

## ğŸ”§ Configuration (Environment Variables)

Create `.env.production`:

```env
# Database
DATABASE_PATH=/app/data/dashboard.duckdb

# Data Sources
SALES_API_URL=https://api.company.com/sales
SALES_API_KEY=your_key_here

# Backup
AWS_S3_BACKUP_BUCKET=company-backups
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret

# User Management
LDAP_SERVER=ldap.company.com
LDAP_PASSWORD=your_password

# Notifications
SLACK_WEBHOOK=https://hooks.slack.com/...
ALERT_EMAIL=alerts@company.com

# Logging
LOG_LEVEL=INFO
LOG_FILE=/app/logs/production.log
```

---

## ğŸ“Š Data Flow: Before vs After

### BEFORE (Demo - Today)
```
App Start
  â†“
Load 100 demo sales records
  â†“
Display dashboard
  â†“
User registers (manual)
  â†“
Static data stays until app restart
```

### AFTER (Production - Tomorrow)
```
App Start
  â†“
Load production DuckDB
  â†“
Background Scheduler Starts
  â†“
Every Hour: Health check
Every Day: 
  - 2 AM: Sync sales from API
  - 3 AM: Backup to S3
  - 4 AM: Cleanup old backups
  â†“
Real-time Updates:
  - User SSO login
  - Webhook from Shopify
  - CSV batch import
  â†“
All changes logged + backed up
```

---

## ğŸ¯ When to Use What

| Scenario | Tool | Command |
|----------|------|---------|
| Testing locally | Demo data | `streamlit run app.py` |
| Import historical CSV | data_sync script | `python scripts/data_sync.py sync-sales --csv file.csv` |
| Daily API sync | APScheduler | Auto runs 2 AM (see schedule) |
| Real-time Shopify | enterprise_integrations | Import & use in data_sync |
| Bulk user import | data_sync script | `python scripts/data_sync.py import-users file.csv` |
| Production deploy | Docker | `docker-compose up -d` |
| Emergency backup | data_sync script | `python scripts/data_sync.py backup` |
| Health check | data_sync script | `python scripts/data_sync.py health-check` |

---

## âš ï¸ Common Issues & Fixes

### Issue: "No sales data showing"
```bash
# Check health
python scripts/data_sync.py health-check

# Import test data
python scripts/data_sync.py sync-sales --csv scripts/example_sales_import.csv

# Verify DB
duckdb data/dashboard.duckdb "SELECT COUNT(*) FROM sales"
```

### Issue: "Scheduler not running"
```bash
# Start it again
python scripts/data_sync.py start-scheduler

# Check logs
tail -f logs/data_sync.log

# Verify APScheduler is installed
pip install apscheduler
```

### Issue: "Backup failed"
```bash
# Check disk space
df -h

# Check permissions
ls -la backups/

# Manual backup
python scripts/data_sync.py backup
```

### Issue: "Users can't login"
```bash
# Check user exists
duckdb data/dashboard.duckdb "SELECT * FROM users"

# Check password hash
# (If importing users, ensure password hash is correct)

# Reset demo users
rm data/dashboard.duckdb
python -c "from src.db import initialize_database; initialize_database()"
```

---

## ğŸ“ˆ Performance Tips

```python
# 1. Use incremental sync (only new data)
python scripts/data_sync.py sync-sales --days 1  # Just yesterday

# 2. Batch large imports
pd.read_csv('file.csv', chunksize=1000)  # Process 1000 at a time

# 3. Add database indexes
db.execute("CREATE INDEX IF NOT EXISTS idx_sales_date ON sales(date)")

# 4. Archive old data
db.execute("DELETE FROM sales WHERE date < DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)")

# 5. Monitor with health checks
python scripts/data_sync.py health-check  # Every hour
```

---

## ğŸš€ Migration Path

```
Week 1: Local Testing
â”œâ”€â”€ Run app locally with demo data
â””â”€â”€ Understand core features

Week 2: Initial Setup
â”œâ”€â”€ Prepare production environment
â”œâ”€â”€ Install dependencies
â””â”€â”€ Create data sync script

Week 3: Data Migration
â”œâ”€â”€ Export historical data
â”œâ”€â”€ Validate data quality
â”œâ”€â”€ Perform initial import
â””â”€â”€ Test all features

Week 4: Automation
â”œâ”€â”€ Setup scheduled syncs
â”œâ”€â”€ Configure monitoring
â”œâ”€â”€ Setup backups
â””â”€â”€ Test recovery

Week 5+: Production
â”œâ”€â”€ Deploy with Docker
â”œâ”€â”€ Monitor 24/7
â”œâ”€â”€ Optimize performance
â””â”€â”€ Scale as needed
```

---

## ğŸ“š Documentation Map

```
You need to...                      Read this...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Understand approaches               PRODUCTION_DATA_STRATEGY.md
Implement data sync                 PRODUCTION_DATA_SYNC_GUIDE.md
Compare demo vs production          DEMO_vs_PRODUCTION_SUMMARY.md
Quick command reference             QUICK_REFERENCE.md (this file)
Setup enterprise integrations       scripts/enterprise_integrations.py
Run locally                         README.md
Deploy to production                docker-compose.yml
Understand architecture             src/db.py
```

---

## ğŸ”‘ Key Files Changed/Added

### Fixed Issues âœ…
- `src/pages/profile.py` - Fixed AttributeError with created_at timestamp

### New Features âœ¨
- `src/sidebar.py` - Advanced sidebar with user profile card & organized navigation
- `scripts/data_sync.py` - Production data synchronization with APScheduler
- `scripts/enterprise_integrations.py` - Pre-built connectors (Shopify, Salesforce, etc.)
- `scripts/example_sales_import.csv` - Sample sales data
- `scripts/example_users_import.csv` - Sample user data

### Updated Files ğŸ“
- `requirements.txt` - Added apscheduler, requests, boto3
- `app.py` - Integrated advanced sidebar

### Documentation ğŸ“–
- `PRODUCTION_DATA_STRATEGY.md` - Complete strategies guide
- `PRODUCTION_DATA_SYNC_GUIDE.md` - Implementation guide
- `DEMO_vs_PRODUCTION_SUMMARY.md` - Detailed comparison
- `QUICK_REFERENCE.md` - This file

---

## âœ… Next Steps

```
1. Fix the bug (DONE)
   â””â”€ Profile page timestamp issue

2. Add advanced navigation (DONE)
   â””â”€ Professional sidebar with user info

3. Explore production data options
   â””â”€ Read PRODUCTION_DATA_STRATEGY.md

4. Implement data sync
   â””â”€ Use scripts/data_sync.py

5. Deploy to production
   â””â”€ docker-compose up -d

6. Monitor & maintain
   â””â”€ Daily health checks
```

---

**Questions?** Check the relevant documentation file above or run:
```bash
python scripts/data_sync.py --help
```